import json
import subprocess
import re
import time
import pymorphy2

INPUT_FILE = "27.json"
BLACKLIST_FILE = "manual_blacklist.json"
WHITELIST_FILE = "manual_whitelist.json"
OUTPUT_FILE = "rubric_context_terms.json"
OLLAMA_MODEL = "nous-hermes2"
MAX_TERMS = 300
PAUSE_BETWEEN_QUERIES = 1.5  # seconds

COMMON_MISPRINTS = {
    "terminologue", "rescarch", "infosecurity", "cybersecurit", "intormation", "electonic",
    "informacion", "informatica", "conrerence", "computar", "libary",
    "citafion", "dessertations", "publising", "publiohing", "fatabases",
    "knowlegde", "infromation", "sorfware", "documantation", "web-site", "interfacial"
}

PSEUDO_ENGLISH_PATTERN = re.compile(r"[^–∞-—è–ê-–Ø—ë–Å]{3,}")

morph = pymorphy2.MorphAnalyzer()

def normalize_term(term: str) -> str:
    words = re.findall(r"\w+", term.lower())
    return " ".join(morph.parse(w)[0].normal_form for w in words)

def is_noise(term: str) -> bool:
    norm = normalize_term(term)
    if len(norm) < 4:
        return True
    if len(norm.split()) < 1:
        return True
    if norm in COMMON_MISPRINTS:
        return True
    if PSEUDO_ENGLISH_PATTERN.fullmatch(norm):
        return True
    if any(stop in norm for stop in ["–¥–∞–Ω–Ω—ã–µ", "–º–µ—Ç–æ–¥", "–æ–±—ä–µ–∫—Ç", "—Å–∏—Å—Ç–µ–º–∞", "–≤–ª–∏—è–Ω–∏–µ", "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç", "–°–°–°–†", "–ú–æ—Å–∫–≤–∞"]):
        return True
    return False

def collect_rubrics(node, collected, parent_title="–ü–∏—â–µ–≤–∞—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç—å"):
    cipher = node.get("cipher")
    title = node.get("title")
    terms = [t["content"] for t in node.get("termList", [])]

    if terms:
        collected.append({
            "cipher": cipher,
            "title": title,
            "terms": terms,
            "parent_title": parent_title
        })

    for child in node.get("children", []):
        collect_rubrics(child, collected, title)

def prefilter_terms(terms, cipher, blacklist, whitelist):
    cleaned = []
    norm_blacklist = set(normalize_term(t) for t in blacklist.get(cipher, []))
    norm_whitelist = set(normalize_term(t) for t in whitelist.get(cipher, []))

    for term in terms:
        norm = normalize_term(term)
        if norm in norm_blacklist:
            continue
        if norm in norm_whitelist:
            cleaned.append(term)
            continue
        if is_noise(term):
            continue
        cleaned.append(term)
    return cleaned

def generate_prompt(cipher, title, parent_title, terms):
    return f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–µ–¥–º–µ—Ç–Ω—ã–º —Ä—É–±—Ä–∏–∫–∞–º –Ω–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. 

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤—ã–±—Ä–∞—Ç—å –æ—Ç 5 –¥–æ 15 –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Ç–æ—á–Ω–æ –æ—Ç—Ä–∞–∂–∞—é—Ç —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ä—É–±—Ä–∏–∫–∏.

üìå –ù–∞–∑–≤–∞–Ω–∏–µ —Ä—É–±—Ä–∏–∫–∏: "{cipher} ‚Äî {title}"
üîó –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è —Ä—É–±—Ä–∏–∫–∞: "{parent_title}"

–í–æ—Ç –æ—á–∏—â–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–µ—Ä–º–∏–Ω–æ–≤: 
{', '.join(terms[:MAX_TERMS])}

‚ùó –£–¥–∞–ª–∏ –∏–∑ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è —Å–ª–∏—à–∫–æ–º –æ–±—â–∏–µ, –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –∏–ª–∏ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–ª–æ–≤–∞.

–û—Ç–≤–µ—Ç –≤–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ –≤ JSON-—Ñ–æ—Ä–º–∞—Ç–µ:
{{
  "cipher": "{cipher}",
  "terms": ["—Ç–µ—Ä–º–∏–Ω1", "—Ç–µ—Ä–º–∏–Ω2", "..."]
}}
""".strip()

def run_ollama_with_retries(prompt: str, retries: int = 5, pause: float = 1.5) -> dict:
    for attempt in range(retries):
        try:
            result = subprocess.run(
                ["ollama", "run", OLLAMA_MODEL],
                input=prompt.encode("utf-8"),
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=90
            )
            output = result.stdout.decode("utf-8", errors="ignore")
            match = re.search(r'{.*}', output, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group())
                except json.JSONDecodeError:
                    pass
            print(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt+1} –Ω–µ—É–¥–∞—á–Ω–∞ –¥–ª—è {prompt[:40]}...")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ø—ã—Ç–∫–∏ {attempt+1}: {e}")
        time.sleep(pause)
    return {}


def main():
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
    with open(BLACKLIST_FILE, "r", encoding="utf-8") as f:
        blacklist = json.load(f)
    with open(WHITELIST_FILE, "r", encoding="utf-8") as f:
        whitelist = json.load(f)

    rubrics = []
    collect_rubrics(data, rubrics)

    results = {}

    for i, rubric in enumerate(rubrics):
        cipher = rubric["cipher"]
        title = rubric["title"]
        parent_title = rubric["parent_title"]
        terms = prefilter_terms(rubric["terms"], cipher, blacklist, whitelist)

        if not terms:
            print(f"[{cipher}] –ü—Ä–æ–ø—É—â–µ–Ω–æ: –Ω–µ—Ç —á–∏—Å—Ç—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤")
            continue

        prompt = generate_prompt(cipher, title, parent_title, terms)
        print(f"[{i+1}/{len(rubrics)}] –û–±—Ä–∞–±–æ—Ç–∫–∞: {cipher} ‚Äî {title} ({len(terms)} —Å–ª–æ–≤)")

        response = run_ollama_with_retries(prompt)
        if not response or "terms" not in response:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –¥–∞–∂–µ –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–æ–≤ –¥–ª—è {cipher}")
            continue

        selected = response["terms"]
        if not isinstance(selected, list) or not all(isinstance(t, str) for t in selected):
            print(f"‚ö†Ô∏è –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç JSON —É {cipher}")
            continue

        results[cipher] = selected
        time.sleep(PAUSE_BETWEEN_QUERIES)

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
